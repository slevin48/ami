Sommet mondial de l'IA : de l'unité et des dissensions
Charlie Perreau
Si 28 gouvernements se sont engagés à travailler ensemble sur les risques liés à l'IA, lors d'un événement organisé à Bletchley, en Angleterre, tous n'ont pas les mêmes points de vue. A contre-emploi, la France préfère mettre l'accent sur l'innovation plutôt que la régulation.
La scène est inédite : Michelle Donelan, secrétaire d'Etat britannique à l'Innovation et à la Technologie, entourée de Gina Raimondo, secrétaire d'Etat américain au Commerce et de Wu Zhaohui, le vice-ministre chinois en charge de la Science et la Tech. Les trois dirigeants se sont exprimés lors de l'AI Safety Summit qui s'est déroulé les 1er et 2 novembre à Bletchley Park, à 80 kilomètres de Londres. « Une rare démonstration d'unité mondiale », note le quotidien « The Guardian ». A la fin de la première journée, 28 pays ont signé une déclaration les engageant à travailler ensemble sur les risques liés à l'intelligence artificielle. Le Royaume-Uni a par la même occasion annoncé la création d'un institut britannique sur la sécurité de l'IA, dont le travail « sera mis à disposition pour le monde », et espère à terme créer un groupe d'experts sur le modèle du Giec pour le climat. A la fin de la seconde journée, le Premier ministre britannique, Rishi Sunak, a annoncé que les nations et entreprises présentes (AWS, Anthropic, Google, Meta, Mistral AI…) travailleront ensemble pour « tester la prochaine génération des modèles d'intelligence artificielle en fonction d'une série de risques critiques pour la sécurité nationale, la sûreté et la société ». Le tout avant qu'ils soient accessibles au public. Les détails concernant ces tests n'ont pas été communiqués.

Un discours trop alarmiste ?
« L'IA ne respecte pas les frontières internationales, il ne faut donc pas travailler en silos », indique aux « Echos » Michelle Donelan. Les différents dirigeants politiques ont fait part, via leurs différentes prises de parole, de leurs inquiétudes communes quant aux mauvais usages de l'IA (désinformation, piratage des données personnelles, facilité à développer des armes chimiques, biologiques et nucléaires…).

Mais les pays ne sont en réalité pas tous alignés et se concurrencent pour prendre le leadership sur les futures régulations. « Ces accords démontrent le leadership global du Royaume-Uni », s'est félicité Rishi Sunak, même si les Etats-Unis ont avant lui annoncé la création de leur propre institut sur la sécurité de l'IA.

Les géants de la tech de leur côté multiplient les avertissements ces derniers mois et appellent à réguler, tout comme les petits nouveaux comme OpenAI. Lors de son audition au Sénat américain au printemps dernier, le patron de la célèbre start-up américaine derrière ChatGPT avait proposé de créer un système de licence pour les modèles d'IA génératives. Une proposition davantage taillée pour les entreprises qui ont des moyens financiers considérables.

« Les cris d'alarme visent à sécuriser leurs monopoles. Et les monopoles appellent les monopoles », grince-t-on du côté des Français présents à l'événement. « Nous sommes méfiants du discours alarmiste des Anglo-Saxons », confie un autre.

La France voit des opportunités à court terme
Un peu à contre-emploi de la culture prudente de la France, Paris se détache avec un discours plus mesuré sur les risques liés à l'IA, même si la France indique qu'il faut évidemment s'occuper des problèmes évoqués. « Il faut s'appuyer sur les ingénieurs, comprendre comment on est arrivé là, quels sont les risques réels et comment on les contrôle. Il ne faut pas céder au complotisme ou au catastrophisme », a confié aux « Echos » Bruno Le Maire, en marge de l'événement.

Le ministre de l'Economie et des Finances ne minimise pas les risques et le besoin de réguler mais préfère mettre au premier plan l'innovation. Réguler les applications basées sur l'IA ? « Ce serait une bonne chose », estime le ministre. Réguler les grands modèles de langages type OpenAI et Mistral AI ? « Ce serait une erreur stratégique », estime-t-il.

Le gouvernement français voit en revanche des opportunités à court terme. « L'IA peut être une réponse pour augmenter le niveau de productivité dans les pays européens. Quand vous regardez la situation économique, les Etats-Unis ont une croissance de 3 ou 4 % alors que les pays européens atteignent 1 %. Nous avons un manque de productivité, de prospérité, de création d'emplois », a déclaré le ministre français, qui a rencontré Sam Altman durant l'événement.

« Avec Bruno Le Maire et Sam Altman, CEO d'OpenAI et créateur de ChatGPT, à Bletchley Park. Nous avons rappelé nos priorités pour l'intelligence artificielle : développer les talents et les technologies en France, agir pour une régulation efficace qui préserve l'innovation », a tweeté Jean-Noël Barrot, ministre délégué chargé de la Transition numérique.

De quoi faire presque oublier le fameux dicton « Les Etats-Unis innove, la Chine copie et l'Europe régule ».